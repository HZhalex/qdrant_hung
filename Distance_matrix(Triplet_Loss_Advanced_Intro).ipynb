{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vQlW7VCBVU1R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "eps = 1e-8 # an arbitrary small value to be used for numerical stability tricks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance_matrix(x):\n",
        "  \"\"\"Efficient computation of Euclidean distance matrix\n",
        "\n",
        "  Args:\n",
        "    x: Input tensor of shape (batch_size, embedding_dim)\n",
        "\n",
        "  Returns:\n",
        "    Distance matrix of shape (batch_size, batch_size)\n",
        "  \"\"\"\n",
        "  # step 1 - compute the dot product\n",
        "\n",
        "  # shape: (batch_size, batch_size)\n",
        "  dot_product = torch.mm(x, x.t())\n",
        "\n",
        "  # step 2 - extract the squared Euclidean norm from the diagonal\n",
        "\n",
        "  # shape: (batch_size,)\n",
        "  squared_norm = torch.diag(dot_product)\n",
        "\n",
        "  # step 3 - compute squared Euclidean distances\n",
        "\n",
        "  # shape: (batch_size, batch_size)\n",
        "  distance_matrix = squared_norm.unsqueeze(0) - 2 * dot_product + squared_norm.unsqueeze(1)\n",
        "\n",
        "  # get rid of negative distances due to numerical instabilities\n",
        "  distance_matrix = F.relu(distance_matrix)\n",
        "\n",
        "  # step 4 - compute the non-squared distances\n",
        "\n",
        "  # handle numerical stability\n",
        "  # derivative of the square root operation applied to 0 is infinite\n",
        "  # we need to handle by setting any 0 to eps\n",
        "  mask = (distance_matrix == 0.0).float()\n",
        "\n",
        "  # use this mask to set indices with a value of 0 to eps\n",
        "  distance_matrix += mask * eps\n",
        "\n",
        "  # now it is safe to get the square root\n",
        "  distance_matrix = torch.sqrt(distance_matrix)\n",
        "\n",
        "  # undo the trick for numerical stability\n",
        "  distance_matrix *= (1.0 - mask)\n",
        "\n",
        "  return distance_matrix"
      ],
      "metadata": {
        "id": "-_fqE-PUV7t8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_triplet_mask(labels):\n",
        "  \"\"\"compute a mask for valid triplets\n",
        "\n",
        "  Args:\n",
        "    labels: Batch of integer labels. shape: (batch_size,)\n",
        "\n",
        "  Returns:\n",
        "    Mask tensor to indicate which triplets are actually valid. Shape: (batch_size, batch_size, batch_size)\n",
        "    A triplet is valid if:\n",
        "    `labels[i] == labels[j] and labels[i] != labels[k]`\n",
        "    and `i`, `j`, `k` are different.\n",
        "  \"\"\"\n",
        "  # step 1 - get a mask for distinct indices\n",
        "\n",
        "  # shape: (batch_size, batch_size)\n",
        "  indices_equal = torch.eye(labels.size()[0], dtype=torch.bool, device=labels.device)\n",
        "  indices_not_equal = torch.logical_not(indices_equal)\n",
        "  # shape: (batch_size, batch_size, 1)\n",
        "  i_not_equal_j = indices_not_equal.unsqueeze(2)\n",
        "  # shape: (batch_size, 1, batch_size)\n",
        "  i_not_equal_k = indices_not_equal.unsqueeze(1)\n",
        "  # shape: (1, batch_size, batch_size)\n",
        "  j_not_equal_k = indices_not_equal.unsqueeze(0)\n",
        "  # Shape: (batch_size, batch_size, batch_size)\n",
        "  distinct_indices = torch.logical_and(torch.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
        "\n",
        "  # step 2 - get a mask for valid anchor-positive-negative triplets\n",
        "\n",
        "  # shape: (batch_size, batch_size)\n",
        "  labels_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
        "  # shape: (batch_size, batch_size, 1)\n",
        "  i_equal_j = labels_equal.unsqueeze(2)\n",
        "  # shape: (batch_size, 1, batch_size)\n",
        "  i_equal_k = labels_equal.unsqueeze(1)\n",
        "  # shape: (batch_size, batch_size, batch_size)\n",
        "  valid_indices = torch.logical_and(i_equal_j, torch.logical_not(i_equal_k))\n",
        "\n",
        "  # step 3 - combine two masks\n",
        "  mask = torch.logical_and(distinct_indices, valid_indices)\n",
        "\n",
        "  return mask"
      ],
      "metadata": {
        "id": "0zKw5AhlV71G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchAllTtripletLoss(nn.Module):\n",
        "  \"\"\"Uses all valid triplets to compute Triplet loss\n",
        "\n",
        "  Args:\n",
        "    margin: Margin value in the Triplet Loss equation\n",
        "  \"\"\"\n",
        "  def __init__(self, margin=1.):\n",
        "    super().__init__()\n",
        "    self.margin = margin\n",
        "\n",
        "  def forward(self, embeddings, labels):\n",
        "    \"\"\"computes loss value.\n",
        "\n",
        "    Args:\n",
        "      embeddings: Batch of embeddings, e.g., output of the encoder. shape: (batch_size, embedding_dim)\n",
        "      labels: Batch of integer labels associated with embeddings. shape: (batch_size,)\n",
        "\n",
        "    Returns:\n",
        "      Scalar loss value.\n",
        "    \"\"\"\n",
        "    # step 1 - get distance matrix\n",
        "    # shape: (batch_size, batch_size)\n",
        "    distance_matrix = euclidean_distance_matrix(embeddings)\n",
        "\n",
        "    # step 2 - compute loss values for all triplets by applying broadcasting to distance matrix\n",
        "\n",
        "    # shape: (batch_size, batch_size, 1)\n",
        "    anchor_positive_dists = distance_matrix.unsqueeze(2)\n",
        "    # shape: (batch_size, 1, batch_size)\n",
        "    anchor_negative_dists = distance_matrix.unsqueeze(1)\n",
        "    # get loss values for all possible n^3 triplets\n",
        "    # shape: (batch_size, batch_size, batch_size)\n",
        "    triplet_loss = anchor_positive_dists - anchor_negative_dists + self.margin\n",
        "\n",
        "    # step 3 - filter out invalid or easy triplets by setting their loss values to 0\n",
        "\n",
        "    # shape: (batch_size, batch_size, batch_size)\n",
        "    mask = get_triplet_mask(labels)\n",
        "    triplet_loss *= mask\n",
        "    # easy triplets have negative loss values\n",
        "    triplet_loss = F.relu(triplet_loss)\n",
        "\n",
        "    # step 4 - compute scalar loss value by averaging positive losses\n",
        "    num_positive_losses = (triplet_loss > eps).float().sum()\n",
        "    triplet_loss = triplet_loss.sum() / (num_positive_losses + eps)\n",
        "\n",
        "    return triplet_loss"
      ],
      "metadata": {
        "id": "6BY1ecDkV73t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "batch_size = 10\n",
        "embedding_dim = 5\n",
        "margin = 1.0\n",
        "\n",
        "# Create dummy embeddings and labels\n",
        "embeddings = torch.randn(batch_size, embedding_dim)\n",
        "labels = torch.randint(0, 3, (batch_size,)) # Example labels (0, 1, or 2)\n",
        "\n",
        "# Instantiate the loss function\n",
        "triplet_loss_fn = BatchAllTtripletLoss(margin=margin)\n",
        "\n",
        "# Compute the loss\n",
        "loss = triplet_loss_fn(embeddings, labels)\n",
        "\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")\n",
        "print(f\"Computed Triplet Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq7RK_qRYCQW",
        "outputId": "71294816-6869-42a7-e7dc-b15a3da82b25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: torch.Size([10, 5])\n",
            "Labels shape: torch.Size([10])\n",
            "Computed Triplet Loss: 1.52973473072052\n"
          ]
        }
      ]
    }
  ]
}